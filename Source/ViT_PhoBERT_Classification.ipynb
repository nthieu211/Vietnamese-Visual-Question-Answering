{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"Ti2q34oPIewJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704536310591,"user_tz":-420,"elapsed":16708,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}},"outputId":"d0741526-7161-4c3e-de0b-0189d2c36770"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.0/468.0 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -q yacs unicodedata2 nltk transformers sentencepiece accelerate transformers[torch]"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kaVxKd9dT6j","outputId":"8381e619-58e6-4e5f-8dd4-9060632e16f8","executionInfo":{"status":"ok","timestamp":1704536331051,"user_tz":-420,"elapsed":20464,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading...\n","From: https://drive.google.com/uc?id=1TztHmmwN8R6MGEABPnxgaBErZ4vDOjdJ\n","To: /content/vivqa-dataset.zip\n","100% 527M/527M [00:08<00:00, 59.9MB/s]\n"]}],"source":["!gdown 1TztHmmwN8R6MGEABPnxgaBErZ4vDOjdJ\n","!unzip -q 'vivqa-dataset.zip'\n","!rm /content/vivqa-dataset.zip"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Uvq5SpGoMKap","outputId":"b53b57db-26c0-408d-9b74-1bab8e787860","executionInfo":{"status":"ok","timestamp":1704536355887,"user_tz":-420,"elapsed":24850,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"2eCn_4HndbGr","executionInfo":{"status":"ok","timestamp":1704536369755,"user_tz":-420,"elapsed":13874,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["import os\n","import re\n","import string\n","import unicodedata\n","import numpy as np\n","import pandas as pd\n","import pickle\n","import shutil\n","from tqdm import tqdm\n","import itertools\n","from PIL import Image\n","from collections import Counter\n","from typing import Dict, List, Union\n","from sklearn.model_selection import train_test_split\n","\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torch.optim import Adam\n","from torch.optim.lr_scheduler import LambdaLR\n","from torch.nn import NLLLoss\n","\n","from transformers import ViTImageProcessor, ViTModel\n","from transformers import PhobertTokenizer\n","from transformers.models.roberta.modeling_roberta import (\n","    RobertaConfig,\n","    RobertaEmbeddings,\n","    RobertaEncoder,\n","    RobertaPreTrainedModel,\n",")"]},{"cell_type":"markdown","metadata":{"id":"O7ZPofYXrfcx"},"source":["# Prepare Dataset"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"GudoE6sEdW4q","executionInfo":{"status":"ok","timestamp":1704536369755,"user_tz":-420,"elapsed":19,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["DATASET_DIR = 'vivqa-dataset'\n","IMAGES_DIR = os.path.join(DATASET_DIR, 'images')\n","TRAIN_PATH = os.path.join(DATASET_DIR, 'train.csv')\n","TEST_PATH = os.path.join(DATASET_DIR, 'test.csv')"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"yMzQSxXfeXuR","executionInfo":{"status":"ok","timestamp":1704536369755,"user_tz":-420,"elapsed":18,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["# Load train.csv\n","train_df = pd.read_csv(TRAIN_PATH)\n","if train_df.shape[1] > 4:\n","    train_df = train_df.iloc[: , 1:] # Drop first column (index)\n","\n","# Load test.csv\n","test_df = pd.read_csv(TEST_PATH)\n","if test_df.shape[1] > 4:\n","    test_df = test_df.iloc[: , 1:] # Drop first column (index)"]},{"cell_type":"markdown","metadata":{"id":"7EDE_MwclkRX"},"source":["## Remove duplicate"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_XnLNvzloK0","outputId":"0be09083-c3d6-4555-ad7d-d248ee154375","executionInfo":{"status":"ok","timestamp":1704536369755,"user_tz":-420,"elapsed":18,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (11819, 4)\n","Test shape: (2987, 4)\n"]}],"source":["# Remove duplicate train_df\n","train_df.drop_duplicates(keep=False, inplace=True)\n","train_df.to_csv(TRAIN_PATH, index=False)\n","print(f'Train shape: {train_df.shape}')\n","\n","# Remove duplicate test_df\n","test_df.drop_duplicates(keep=False, inplace=True)\n","test_df.to_csv(TEST_PATH, index=False)\n","print(f'Test shape: {test_df.shape}')"]},{"cell_type":"markdown","metadata":{"id":"SWCtfCp1chs5"},"source":["# Config"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mowwbb_Pclpt","outputId":"0176e8cb-515c-4226-892d-2bd05008d023","executionInfo":{"status":"ok","timestamp":1704536370434,"user_tz":-420,"elapsed":696,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["vit_phobert_classification\n"]}],"source":["from yacs.config import CfgNode\n","import yaml\n","\n","if os.path.exists('/content/drive'):\n","    BASE_DIR = '/content/drive/MyDrive'\n","else:\n","    BASE_DIR = ''\n","\n","config_file = os.path.join(BASE_DIR, \"ViVQA-Models\", \"vit_phobert_classification.yaml\")\n","\n","with open(config_file, \"r\") as stream:\n","    try:\n","        CONFIG =  CfgNode(init_dict=yaml.safe_load(stream))\n","    except yaml.YAMLError as exc:\n","        print(exc)\n","\n","print(CONFIG.MODEL.NAME)"]},{"cell_type":"markdown","metadata":{"id":"FBiskLU1lorL"},"source":["# Build dataset"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"mUxwmLANDLCC","executionInfo":{"status":"ok","timestamp":1704536370435,"user_tz":-420,"elapsed":7,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["class ClassificationVocab(object):\n","    # This class is especially designed for ViVQA dataset by treating the VQA as a classification task.\n","    # For more information, please visit https://arxiv.org/abs/1708.02711\n","\n","    def __init__(self, config):\n","\n","        self.tokenizer = config.TOKENIZER\n","\n","        self.padding_token = config.PAD_TOKEN\n","        self.bos_token = config.BOS_TOKEN\n","        self.eos_token = config.EOS_TOKEN\n","        self.unk_token = config.UNK_TOKEN\n","\n","        self.make_vocab([\n","            config.DF_PATH.TRAIN,\n","            config.DF_PATH.TEST\n","        ])\n","\n","        counter = self.freqs.copy()\n","\n","        min_freq = max(config.MIN_FREQ, 1)\n","\n","        specials = [self.padding_token, self.bos_token, self.eos_token, self.unk_token]\n","        itos = specials\n","        # frequencies of special tokens are not counted when building vocabulary\n","        # in frequency order\n","        for tok in specials:\n","            del counter[tok]\n","\n","        # sort by frequency, then alphabetically\n","        words_and_frequencies = sorted(counter.items(), key=lambda tup: tup[0])\n","        words_and_frequencies.sort(key=lambda tup: tup[1], reverse=True)\n","\n","        for word, freq in words_and_frequencies:\n","            if freq < min_freq:\n","                break\n","            itos.append(word)\n","\n","        self.itos = {i: tok for i, tok in enumerate(itos)}\n","        self.stoi = {tok: i for i, tok in enumerate(itos)}\n","\n","        self.specials = [self.padding_token, self.bos_token, self.eos_token, self.unk_token]\n","\n","        self.padding_idx = self.stoi[self.padding_token]\n","        self.bos_idx = self.stoi[self.bos_token]\n","        self.eos_idx = self.stoi[self.eos_token]\n","        self.unk_idx = self.stoi[self.unk_token]\n","\n","\n","    def make_vocab(self, df_path_list):\n","        self.freqs = Counter()\n","        itoa = set()\n","        self.max_question_length = 0\n","        for df_path in df_path_list:\n","            df = pd.read_csv(df_path)\n","            for question in df['question']:\n","                question = preprocess_sentence(question, self.tokenizer)\n","                self.freqs.update(question)\n","                if len(question) + 2 > self.max_question_length:\n","                    self.max_question_length = len(question) + 2\n","            for answer in df['answer']:\n","                answer = \" \".join(preprocess_sentence(answer, self.tokenizer))\n","                itoa.add(answer)\n","\n","        self.itoa = {ith: answer for ith, answer in enumerate(itoa)}\n","        self.atoi = {answer: ith for ith, answer in self.itoa.items()}\n","        self.total_answers = len(self.atoi)\n","\n","    def encode_question(self, question: List[str]) -> torch.Tensor:\n","        \"\"\" Turn a question into a vector of indices and a question length \"\"\"\n","        vec = torch.ones(self.max_question_length).long() * self.padding_idx\n","        for i, token in enumerate([self.bos_token] + question + [self.eos_token]):\n","            vec[i] = self.stoi[token] if token in self.stoi else self.unk_idx\n","        return vec\n","\n","    def encode_answer(self, answer: List[str]) -> torch.Tensor:\n","        answer = \" \".join(answer)\n","        return torch.tensor([self.atoi[answer]], dtype=torch.long)\n","\n","    def decode_question(self, question_vecs: torch.Tensor, join_words=True) -> List[str]:\n","        '''\n","            question_vecs: (bs, max_length)\n","        '''\n","        questions = []\n","        for vec in question_vecs:\n","            question = \" \".join([self.itos[idx] for idx in vec.tolist() if self.itos[idx] not in self.specials])\n","            if join_words:\n","                questions.append(question)\n","            else:\n","                questions.append(question.strip().split())\n","        return questions\n","\n","    def decode_answer(self, answer_vecs: torch.Tensor, join_word=False) -> Union[List[str], List[List[str]]]:\n","        answers = []\n","        list_answers = answer_vecs.tolist()\n","        for answer_idx in list_answers:\n","            ans_i = self.itoa[answer_idx] if join_word else self.itoa[answer_idx].split()\n","            answers.append(str(ans_i))\n","        return answers"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"cZVZT4vbiuJe","executionInfo":{"status":"ok","timestamp":1704536370435,"user_tz":-420,"elapsed":6,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["# Build dataset class\n","class ViVQA_Dataset(torch.utils.data.Dataset):\n","  \"\"\"\n","  Dataset class for the ViVQA dataset.\n","  \"\"\"\n","  def __init__(self, df, img_dir, vocab):\n","    self.df = df\n","    self.img_dir = img_dir\n","    self.vocab = vocab\n","\n","  def __len__(self):\n","    return self.df.shape[0]\n","\n","  def __getitem__(self, idx):\n","    question = self.df.loc[idx, 'question']\n","    answer = self.df.loc[idx, 'answer']\n","    image_id = self.df.loc[idx, 'img_id']\n","    quest_type = self.df.loc[idx, 'type']\n","\n","    img_file = os.path.join(self.img_dir, f'image_{image_id}.jpg')\n","\n","    return {'image':img_file, 'question':question, 'answer':answer}"]},{"cell_type":"markdown","metadata":{"id":"DuwJAzxaC0X3"},"source":["# Metrics"]},{"cell_type":"markdown","metadata":{"id":"k4k64XQEC0X3"},"source":["## CIDEr"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"RrxK82_hC0X3","executionInfo":{"status":"ok","timestamp":1704536370435,"user_tz":-420,"elapsed":6,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["import copy\n","from collections import defaultdict\n","import math\n","\n","def precook(s, n=4):\n","    \"\"\"\n","    Takes a string as input and returns an object that can be given to\n","    either cook_refs or cook_test. This is optional: cook_refs and cook_test\n","    can take string arguments as well.\n","    :param s: string : sentence to be converted into ngrams\n","    :param n: int    : number of ngrams for which representation is calculated\n","    :return: term frequency vector for occuring ngrams\n","    \"\"\"\n","    words = str(s).split()\n","    counts = defaultdict(int)\n","    for k in range(1,n+1):\n","        for i in range(len(words)-k+1):\n","            ngram = tuple(words[i:i+k])\n","            counts[ngram] += 1\n","    return counts\n","\n","def cook_refs(refs, n=4): ## lhuang: oracle will call with \"average\"\n","    '''Takes a list of reference sentences for a single segment\n","    and returns an object that encapsulates everything that BLEU\n","    needs to know about them.\n","    :param refs: list of string : reference sentences for some image\n","    :param n: int : number of ngrams for which (ngram) representation is calculated\n","    :return: result (list of dict)\n","    '''\n","    return [precook(ref, n) for ref in refs]\n","\n","def cook_test(test, n=4):\n","    '''Takes a test sentence and returns an object that\n","    encapsulates everything that BLEU needs to know about it.\n","    :param test: list of string : hypothesis sentence for some image\n","    :param n: int : number of ngrams for which (ngram) representation is calculated\n","    :return: result (dict)\n","    '''\n","    return precook(test, n)\n","\n","class CiderScorer(object):\n","    \"\"\"CIDEr scorer.\n","    \"\"\"\n","\n","    def __init__(self, refs, test=None, n=4, sigma=6.0, doc_frequency=None, ref_len=None):\n","        ''' singular instance '''\n","        self.n = n\n","        self.sigma = sigma\n","        self.crefs = []\n","        self.ctest = []\n","        self.doc_frequency = defaultdict(float)\n","        self.ref_len = None\n","\n","        for k in range(len(refs)):\n","            self.crefs.append(cook_refs(refs[k]))\n","            if test is not None:\n","                self.ctest.append(cook_test(test[k][0]))  ## N.B.: -1\n","            else:\n","                self.ctest.append(None)  # lens of crefs and ctest have to match\n","\n","        if doc_frequency is None and ref_len is None:\n","            # compute idf\n","            self.compute_doc_freq()\n","            # compute log reference length\n","            self.ref_len = np.log(float(len(self.crefs)))\n","        else:\n","            self.doc_frequency = doc_frequency\n","            self.ref_len = ref_len\n","\n","    def compute_doc_freq(self):\n","        '''\n","        Compute term frequency for reference data.\n","        This will be used to compute idf (inverse document frequency later)\n","        The term frequency is stored in the object\n","        :return: None\n","        '''\n","        for refs in self.crefs:\n","            # refs, k ref captions of one image\n","            for ngram in set([ngram for ref in refs for (ngram,count) in ref.items()]):\n","                self.doc_frequency[ngram] += 1\n","            # maxcounts[ngram] = max(maxcounts.get(ngram,0), count)\n","\n","    def compute_cider(self):\n","        def counts2vec(cnts):\n","            \"\"\"\n","            Function maps counts of ngram to vector of tfidf weights.\n","            The function returns vec, an array of dictionary that store mapping of n-gram and tf-idf weights.\n","            The n-th entry of array denotes length of n-grams.\n","            :param cnts:\n","            :return: vec (array of dict), norm (array of float), length (int)\n","            \"\"\"\n","            vec = [defaultdict(float) for _ in range(self.n)]\n","            length = 0\n","            norm = [0.0 for _ in range(self.n)]\n","            for (ngram,term_freq) in cnts.items():\n","                # give word count 1 if it doesn't appear in reference corpus\n","                df = np.log(max(1.0, self.doc_frequency[ngram]))\n","                # ngram index\n","                n = len(ngram)-1\n","                # tf (term_freq) * idf (precomputed idf) for n-grams\n","                vec[n][ngram] = float(term_freq)*(self.ref_len - df)\n","                # compute norm for the vector.  the norm will be used for computing similarity\n","                norm[n] += pow(vec[n][ngram], 2)\n","\n","                if n == 1:\n","                    length += term_freq\n","            norm = [np.sqrt(n) for n in norm]\n","            return vec, norm, length\n","\n","        def sim(vec_hyp, vec_ref, norm_hyp, norm_ref, length_hyp, length_ref):\n","            '''\n","            Compute the cosine similarity of two vectors.\n","            :param vec_hyp: array of dictionary for vector corresponding to hypothesis\n","            :param vec_ref: array of dictionary for vector corresponding to reference\n","            :param norm_hyp: array of float for vector corresponding to hypothesis\n","            :param norm_ref: array of float for vector corresponding to reference\n","            :param length_hyp: int containing length of hypothesis\n","            :param length_ref: int containing length of reference\n","            :return: array of score for each n-grams cosine similarity\n","            '''\n","            delta = float(length_hyp - length_ref)\n","            # measure consine similarity\n","            val = np.array([0.0 for _ in range(self.n)])\n","            for n in range(self.n):\n","                # ngram\n","                for (ngram,count) in vec_hyp[n].items():\n","                    # vrama91 : added clipping\n","                    val[n] += min(vec_hyp[n][ngram], vec_ref[n][ngram]) * vec_ref[n][ngram]\n","\n","                if (norm_hyp[n] != 0) and (norm_ref[n] != 0):\n","                    val[n] /= (norm_hyp[n]*norm_ref[n])\n","\n","                assert(not math.isnan(val[n]))\n","                # vrama91: added a length based gaussian penalty\n","                val[n] *= np.e**(-(delta**2)/(2*self.sigma**2))\n","            return val\n","\n","        scores = []\n","        for test, refs in zip(self.ctest, self.crefs):\n","            # compute vector for test captions\n","            vec, norm, length = counts2vec(test)\n","            # compute vector for ref captions\n","            score = np.array([0.0 for _ in range(self.n)])\n","            for ref in refs:\n","                vec_ref, norm_ref, length_ref = counts2vec(ref)\n","                score += sim(vec, vec_ref, norm, norm_ref, length, length_ref)\n","            # change by vrama91 - mean of ngram scores, instead of sum\n","            score_avg = np.mean(score)\n","            # divide by number of references\n","            score_avg /= len(refs)\n","            # multiply score by 10\n","            score_avg *= 10.0\n","            # append score of an image to the score list\n","            scores.append(score_avg)\n","        return scores\n","\n","    def compute_score(self):\n","        # compute cider score\n","        score = self.compute_cider()\n","        # debug\n","        # print score\n","        return np.mean(np.array(score)), np.array(score)"]},{"cell_type":"markdown","metadata":{"id":"-lj_4auvC0X4"},"source":["## Extract match"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"rQGzKVxpC0X4","executionInfo":{"status":"ok","timestamp":1704536370435,"user_tz":-420,"elapsed":6,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["class Exact_Match:\n","    def compute_score(self, y_true, y_pred):\n","        if y_true==y_pred:\n","            return 1\n","        else:\n","            return 0"]},{"cell_type":"markdown","metadata":{"id":"CgJsda56C0X4"},"source":["## F1 Score"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"LgoSZQshC0X4","executionInfo":{"status":"ok","timestamp":1704536370435,"user_tz":-420,"elapsed":6,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["class F1:\n","  def Precision(self,y_true,y_pred):\n","    if y_pred is None:\n","       return 0\n","    common = set(y_true) & set(y_pred)\n","    return len(common) / len(set(y_pred))\n","\n","  def Recall(self,y_true,y_pred):\n","    common = set(y_true) & set(y_pred)\n","    return len(common) / len(set(y_true))\n","\n","  def compute_score(self,y_true,y_pred):\n","    if len(y_pred) == 0 or len(y_true) == 0:\n","        return int(y_pred == y_true)\n","\n","    precision = self.Precision(y_true, y_pred)\n","    recall = self.Recall(y_true, y_pred)\n","\n","    if precision == 0 or recall == 0:\n","        return 0\n","    f1 = 2*precision*recall / (precision+recall)\n","    return f1"]},{"cell_type":"markdown","metadata":{"id":"jB8bXph0C0X4"},"source":["## Wup"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F5oZ1YZCC0X5","outputId":"f1c6bd44-9bcc-490e-c53e-f7f3c0edb7de","executionInfo":{"status":"ok","timestamp":1704536371079,"user_tz":-420,"elapsed":649,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]}],"source":["import nltk\n","nltk.download('wordnet')\n","from nltk.corpus import wordnet\n","\n","class Wup:\n","    def get_semantic_field(self,a):\n","        weight = 1.0\n","        semantic_field = wordnet.synsets(str(a), pos=wordnet.NOUN)\n","        return (semantic_field,weight)\n","\n","    def get_stem_word(self,a):\n","        \"\"\"\n","        Sometimes answer has form word\\d+:wordid.\n","        If so we return word and downweight\n","        \"\"\"\n","        weight = 1.0\n","        return (a,weight)\n","    def compute_score(self, a: str, b: str, similarity_threshold: float = 0.9):\n","        \"\"\"\n","        Returns Wu-Palmer similarity score.\n","        More specifically, it computes:\n","            max_{x \\in interp(a)} max_{y \\in interp(b)} wup(x,y)\n","            where interp is a 'interpretation field'\n","        \"\"\"\n","        global_weight=1.0\n","\n","        (a,global_weight_a)=self.get_stem_word(a)\n","        (b,global_weight_b)=self.get_stem_word(b)\n","        global_weight = min(global_weight_a,global_weight_b)\n","\n","        if a==b:\n","            # they are the same\n","            return 1.0*global_weight\n","\n","        if a==[] or b==[]:\n","            return 0\n","\n","        interp_a,weight_a = self.get_semantic_field(a)\n","        interp_b,weight_b = self.get_semantic_field(b)\n","\n","        if interp_a == [] or interp_b == []:\n","            return 0\n","\n","        # we take the most optimistic interpretation\n","        global_max=0.0\n","        for x in interp_a:\n","            for y in interp_b:\n","                local_score=x.wup_similarity(y)\n","                if local_score > global_max:\n","                    global_max=local_score\n","\n","        # we need to use the semantic fields and therefore we downweight\n","        # unless the score is high which indicates both are synonyms\n","        if global_max < similarity_threshold:\n","            interp_weight = 0.1\n","        else:\n","            interp_weight = 1.0\n","\n","        final_score=global_max*weight_a*weight_b*interp_weight*global_weight\n","        return final_score"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"MKbHQ5FTC0X5","executionInfo":{"status":"ok","timestamp":1704536371079,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["import re\n","import unicodedata\n","\n","def normalize_text(text):\n","    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n","    text = text.lower().strip()\n","    return text\n","\n","def preprocess_sentence(sentence: str, tokenizer=None):\n","    sentence = sentence.lower()\n","    sentence = unicodedata.normalize('NFC', sentence)\n","    sentence = re.sub(r\"[“”]\", \"\\\"\", sentence)\n","    sentence = re.sub(r\"!\", \" ! \", sentence)\n","    sentence = re.sub(r\"\\?\", \" ? \", sentence)\n","    sentence = re.sub(r\":\", \" : \", sentence)\n","    sentence = re.sub(r\";\", \" ; \", sentence)\n","    sentence = re.sub(r\",\", \" , \", sentence)\n","    sentence = re.sub(r\"\\\"\", \" \\\" \", sentence)\n","    sentence = re.sub(r\"'\", \" ' \", sentence)\n","    sentence = re.sub(r\"\\(\", \" ( \", sentence)\n","    sentence = re.sub(r\"\\[\", \" [ \", sentence)\n","    sentence = re.sub(r\"\\)\", \" ) \", sentence)\n","    sentence = re.sub(r\"\\]\", \" ] \", sentence)\n","    sentence = re.sub(r\"/\", \" / \", sentence)\n","    sentence = re.sub(r\"\\.\", \" . \", sentence)\n","    sentence = re.sub(r\"-\", \" - \", sentence)\n","    sentence = re.sub(r\"\\$\", \" $ \", sentence)\n","    sentence = re.sub(r\"\\&\", \" & \", sentence)\n","    sentence = re.sub(r\"\\*\", \" * \", sentence)\n","    # tokenize the sentence\n","    if tokenizer is None:\n","        tokenizer = lambda s: s\n","    sentence = tokenizer(sentence)\n","    sentence = \" \".join(sentence.strip().split()) # remove duplicated spaces\n","    tokens = sentence.strip().split()\n","\n","    return tokens\n","\n","class ScoreCalculator:\n","    def __init__(self):\n","        self.f1_caculate=F1()\n","        self.em_caculate=Exact_Match()\n","        self.Wup_caculate=Wup()\n","    #F1 score character level\n","    def f1_char(self,labels: List[str], preds: List[str]) -> float:\n","        scores=[]\n","        for i in range(len(labels)):\n","            scores.append(self.f1_caculate.compute_score(str(preprocess_sentence(normalize_text(labels[i]))).split(),str(preprocess_sentence(normalize_text(preds[i]))).split()))\n","        return np.mean(scores)\n","\n","    #F1 score token level\n","    def f1_token(self,labels: List[str], preds: List[str]) -> float:\n","        scores=[]\n","        for i in range(len(labels)):\n","            scores.append(self.f1_caculate.compute_score(str(preprocess_sentence(normalize_text(labels[i]))).split(),str(preprocess_sentence(normalize_text(preds[i]))).split()))\n","        return np.mean(scores)\n","    #Excat match score\n","    def em(self,labels: List[str], preds: List[str]) -> float:\n","        scores=[]\n","        for i in range(len(labels)):\n","            scores.append(self.em_caculate.compute_score(str(preprocess_sentence(normalize_text(labels[i]))).split(),str(preprocess_sentence(normalize_text(preds[i]))).split()))\n","        return np.mean(scores)\n","    #Wup score\n","    def wup(self,labels: List[str], preds: List[str]) -> float:\n","        scores=[]\n","        for i in range(len(labels)):\n","            scores.append(self.Wup_caculate.compute_score(str(preprocess_sentence(normalize_text(labels[i]))).split(),str(preprocess_sentence(normalize_text(preds[i]))).split()))\n","        return np.mean(scores)\n","    #Cider score\n","    def cider_score(self,labels: List[str], preds: List[str]) -> float:\n","        labels=[[preprocess_sentence(normalize_text(label))] for label in labels]\n","        preds=[[preprocess_sentence(normalize_text(pred))] for pred in preds ]\n","        cider_caculate= CiderScorer(labels, test=preds, n=4, sigma=6.)\n","        scores,_=cider_caculate.compute_score()\n","        return scores"]},{"cell_type":"markdown","metadata":{"id":"rZTiCWMorZwl"},"source":["# Model"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"XbV9ipS5aP_D","executionInfo":{"status":"ok","timestamp":1704536371080,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["def generate_padding_mask(sequences, padding_idx: int) -> torch.BoolTensor:\n","    '''\n","        sequences: (bs, seq_len, dim)\n","    '''\n","    if sequences is None:\n","        return None\n","\n","    if len(sequences.shape) == 2: # (bs, seq_len)\n","        __seq = sequences.unsqueeze(dim=-1) # (bs, seq_len, 1)\n","    else:\n","        __seq = sequences\n","\n","    mask = (torch.sum(__seq, dim=-1) == (padding_idx*__seq.shape[-1])).long() * -10e4 # (b_s, seq_len)\n","    return mask.unsqueeze(1).unsqueeze(1) # (bs, 1, 1, seq_len)\n","\n","class TextBert(RobertaPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","\n","        self.embeddings = RobertaEmbeddings(config)\n","        self.encoder = RobertaEncoder(config)\n","        self.init_weights()\n","\n","    def forward(self, txt_inds, txt_mask):\n","        encoder_inputs = self.embeddings(txt_inds)\n","\n","        attention_mask = txt_mask\n","        head_mask = [None] * self.config.num_hidden_layers\n","        encoder_outputs = self.encoder(\n","            encoder_inputs, attention_mask, head_mask=head_mask\n","        )\n","        seq_output = encoder_outputs[0]\n","\n","        return seq_output\n","\n","class RobertaEmbedding(nn.Module):\n","    def __init__(self, config, vocab):\n","        super().__init__()\n","\n","        self.device = config.DEVICE\n","\n","        roberta_config = RobertaConfig.from_pretrained(config.PRETRAINED_NAME)\n","\n","        self.tokenizer = PhobertTokenizer.from_pretrained(config.PRETRAINED_NAME)\n","        self.embedding = TextBert(roberta_config)\n","        self.embedding = self.embedding.from_pretrained(config.PRETRAINED_NAME)\n","\n","        # freeze all parameters of pretrained model\n","        for param in self.embedding.parameters():\n","            param.requires_grad = False\n","\n","        self.proj = nn.Linear(config.D_PRETRAINED_FEATURE, config.D_MODEL)\n","        self.gelu = nn.GELU()\n","        self.dropout = nn.Dropout(config.DROPOUT)\n","\n","    def forward(self, questions: List[str]):\n","        inputs = self.tokenizer(questions, return_tensors=\"pt\", padding=True).input_ids.to(self.device)\n","        padding_mask = generate_padding_mask(inputs, padding_idx=self.tokenizer.pad_token_id)\n","        features = self.embedding(inputs, padding_mask)\n","\n","        out = self.proj(features)\n","        out = self.dropout(self.gelu(out))\n","\n","        return out, padding_mask"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"G2X9xa1TedZh","executionInfo":{"status":"ok","timestamp":1704536371080,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["class ViTEmbedding(nn.Module):\n","    def __init__(self, config):\n","        super().__init__()\n","\n","        self.device = torch.device(config.DEVICE)\n","\n","        self.feature_extractor = ViTImageProcessor.from_pretrained(config.PRETRAINED_NAME)\n","        self.backbone = ViTModel.from_pretrained(config.PRETRAINED_NAME)\n","        # freeze all parameters of pretrained model\n","        for param in self.backbone.parameters():\n","            param.requires_grad = False\n","\n","        self.proj = nn.Linear(config.D_PRETRAINED_FEATURE, config.D_MODEL)\n","        self.gelu = nn.GELU()\n","        self.dropout = nn.Dropout(config.DROPOUT)\n","\n","    def forward(self, images: List[Image.Image]):\n","        inputs = self.feature_extractor(images, return_tensors=\"pt\").to(self.device)\n","        features = self.backbone(**inputs).last_hidden_state\n","        padding_mask = generate_padding_mask(features, padding_idx=0)\n","\n","        out = self.proj(features)\n","        out = self.dropout(self.gelu(out))\n","\n","        return out, padding_mask"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"GbiSGSo8eiH_","executionInfo":{"status":"ok","timestamp":1704536371080,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["class ViTmBERTClassification(nn.Module):\n","    def __init__(self, config, vocab):\n","        super().__init__()\n","        self.d_model = config.D_MODEL\n","\n","        self.text_embedding = RobertaEmbedding(config.TEXT_EMBEDDING, vocab)\n","        self.vision_encoder = ViTEmbedding(config.VISION_EMBEDDING)\n","\n","        self.fusion = nn.Linear(config.D_MODEL, config.D_MODEL)\n","        self.dropout = nn.Dropout(config.DROPOUT)\n","        self.norm = nn.LayerNorm(config.D_MODEL)\n","\n","        self.proj = nn.Linear(config.D_MODEL, vocab.total_answers)\n","\n","    def init_weights(self):\n","        for p in self.parameters():\n","            if p.dim() > 1:\n","                nn.init.xavier_uniform_(p)\n","\n","    def forward(self, questions: List[str], images: List[str]):\n","        images = [Image.open(image_path).convert(\"RGB\")  for image_path in images]\n","        vision_features,_ = self.vision_encoder(images)\n","        text_features,_ = self.text_embedding(questions)\n","\n","        fused_features = torch.cat([vision_features, text_features], dim=1)\n","        fused_features = self.dropout(self.fusion(fused_features))\n","        out = fused_features.sum(dim=1)\n","        out = self.proj(out)\n","\n","        return F.log_softmax(out, dim=-1)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"VFDXxPJ6ekrd","executionInfo":{"status":"ok","timestamp":1704536371080,"user_tz":-420,"elapsed":5,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["class ClassificationTask():\n","    def __init__(self, config):\n","        # Create checkpoint folder if not existed\n","        self.checkpoint_path = os.path.join(BASE_DIR, config.TRAINING.CHECKPOINT_PATH, config.MODEL.NAME)\n","        if not os.path.isdir(self.checkpoint_path):\n","            print(\"Creating checkpoint path\")\n","            os.makedirs(self.checkpoint_path)\n","\n","        # Create/Load vocab\n","        if not os.path.isfile(os.path.join(self.checkpoint_path, \"vocab.bin\")):\n","            print(\"Creating vocab\")\n","            self.load_vocab(config.DATASET.VOCAB)\n","            print(\"Saving vocab to %s\" % os.path.join(self.checkpoint_path, \"vocab.bin\"))\n","            pickle.dump(self.vocab, open(os.path.join(self.checkpoint_path, \"vocab.bin\"), \"wb\"))\n","        else:\n","            print(\"Loading vocab from %s\" % os.path.join(self.checkpoint_path, \"vocab.bin\"))\n","            self.vocab = pickle.load(open(os.path.join(self.checkpoint_path, \"vocab.bin\"), \"rb\"))\n","\n","        print(\"Loading data\")\n","        self.load_dataset(config)\n","        self.create_dataloader(config)\n","\n","        self.config = config\n","        self.device = torch.device(config.MODEL.DEVICE)\n","        self.model = ViTmBERTClassification(config.MODEL, self.vocab)\n","        self.model.to(self.device)\n","\n","        # Init hyperparameters\n","        self.epoch = 0\n","        self.score = config.TRAINING.SCORE\n","        self.score_value = 0.\n","        self.compute_score = ScoreCalculator()\n","        self.learning_rate = config.TRAINING.LEARNING_RATE\n","        self.patience = config.TRAINING.PATIENCE\n","\n","        self.optim = Adam(self.model.parameters(), lr=config.TRAINING.LEARNING_RATE, betas=(0.9, 0.98))\n","        lambda_epoch = lambda epoch: 0.95 ** epoch\n","        self.scheduler = LambdaLR(self.optim, lr_lambda=lambda_epoch)\n","        self.loss_fn = NLLLoss(ignore_index=self.vocab.padding_idx)\n","\n","    def load_vocab(self, config):\n","        self.vocab = ClassificationVocab(config)\n","\n","    def load_dataset(self, config):\n","        train_df = pd.read_csv(config.DATASET.DF_PATH.TRAIN)\n","        X = train_df[['question', 'answer', 'img_id', 'type']]\n","        # Add a dummy target variable\n","        train_df['dummy_target'] = train_df['type']\n","        train_X, valid_X, train_dummy, valid_dummy = train_test_split(X, train_df['dummy_target'], test_size=0.2, random_state=42, stratify=train_df['dummy_target'])\n","        # Create dataframes for training and validation sets\n","        train_df = pd.DataFrame({'question': train_X['question'], 'answer': train_X['answer'], 'img_id': train_X['img_id'], 'type': train_X['type']})\n","        valid_df = pd.DataFrame({'question': valid_X['question'], 'answer': valid_X['answer'], 'img_id': valid_X['img_id'], 'type': valid_X['type']})\n","        train_df.reset_index(drop=True, inplace=True)\n","        valid_df.reset_index(drop=True, inplace=True)\n","        test_df = pd.read_csv(config.DATASET.DF_PATH.TEST)\n","        self.train_dataset = ViVQA_Dataset(train_df, config.DATASET.FEATURE_PATH.IMAGE, self.vocab)\n","        self.valid_dataset = ViVQA_Dataset(valid_df, config.DATASET.FEATURE_PATH.IMAGE, self.vocab)\n","        self.test_dataset = ViVQA_Dataset(test_df, config.DATASET.FEATURE_PATH.IMAGE, self.vocab)\n","        print(f'[INFO] Train size: {len(self.train_dataset)}')\n","        print(f'[INFO] Valid size: {len(self.valid_dataset)}')\n","        print(f'[INFO] Test size: {len(self.test_dataset)}')\n","\n","    def create_dataloader(self, config):\n","        self.train_dataloader = DataLoader(self.train_dataset, batch_size=config.DATASET.BATCH_SIZE, shuffle=True, num_workers=config.DATASET.WORKERS)\n","        self.valid_dataloader = DataLoader(self.valid_dataset, batch_size=config.DATASET.BATCH_SIZE, shuffle=False, num_workers=config.DATASET.WORKERS)\n","        self.test_dataloader = DataLoader(self.test_dataset, batch_size=config.DATASET.BATCH_SIZE, shuffle=False, num_workers=config.DATASET.WORKERS)\n","\n","    def load_checkpoint(self, fname) -> dict:\n","        if not os.path.exists(fname):\n","            return None\n","        print(f\"Loading checkpoint from {fname}\")\n","        checkpoint = torch.load(fname)\n","        self.score_value = checkpoint['score_value']\n","        self.model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n","        self.optim.load_state_dict(checkpoint['optimizer_state_dict'])\n","        return checkpoint\n","\n","    def save_checkpoint(self) -> None:\n","        dict_for_saving = {\n","            'epoch': self.epoch,\n","            'model_state_dict': self.model.state_dict(),\n","            'optimizer_state_dict': self.optim.state_dict(),\n","            'score_value': self.score_value,\n","        }\n","        torch.save(dict_for_saving, os.path.join(self.checkpoint_path, \"last_model.pth\"))\n","\n","    def evaluate_loss(self, dataloader: DataLoader):\n","        self.model.eval()\n","        running_loss = .0\n","        with tqdm(desc='Epoch %d - Validation' % self.epoch, unit='it', total=len(dataloader)) as pbar:\n","            with torch.no_grad():\n","                for it, items in enumerate(dataloader):\n","                    quest, img, answer = items['question'], items['image'], items['answer']\n","                    with torch.no_grad():\n","                        out = self.model(quest, img).contiguous()\n","\n","                    answer = torch.stack([self.vocab.encode_answer(preprocess_sentence(ans, self.vocab.tokenizer)) for ans in answer]).to(self.device)\n","                    loss = self.loss_fn(out.view(-1, self.vocab.total_answers), answer.view(-1))\n","                    this_loss = loss.item()\n","                    running_loss += this_loss\n","\n","                    pbar.set_postfix(loss=running_loss / (it + 1))\n","                    pbar.update()\n","\n","        val_loss = running_loss / len(dataloader)\n","        return val_loss\n","\n","    def evaluate_metrics(self, dataloader: DataLoader):\n","        self.model.eval()\n","        wups=0.\n","        em=0.\n","        f1=0.\n","        cider=0.\n","        with tqdm(desc='Epoch %d - Evaluation' % self.epoch, unit='it', total=len(dataloader)) as pbar:\n","            for it, items in enumerate(dataloader):\n","                quest, img, answer = items['question'], items['image'], items['answer']\n","                with torch.no_grad():\n","                    outs = self.model(quest, img).contiguous()\n","\n","                answer = torch.stack([self.vocab.encode_answer(preprocess_sentence(ans, self.vocab.tokenizer)) for ans in answer]).to(self.device)\n","                answers_gt = self.vocab.decode_answer(answer.squeeze(-1), join_word=True)\n","                answers_gen = self.vocab.decode_answer(outs.argmax(dim=-1), join_word=True)\n","\n","                wups+=self.compute_score.wup(answers_gt, answers_gen)\n","                em+=self.compute_score.em(answers_gt, answers_gen)\n","                f1+=self.compute_score.f1_token(answers_gt, answers_gen)\n","                cider+=self.compute_score.cider_score(answers_gt, answers_gen)\n","                pbar.update()\n","\n","        scores ={\n","            'wups':wups/len(dataloader),\n","            'em':em/len(dataloader),\n","            'f1':f1/len(dataloader),\n","            'cider':cider/len(dataloader)\n","        }\n","        return scores\n","\n","    def train(self):\n","        self.model.train()\n","        running_loss = .0\n","        with tqdm(desc='Epoch %d - Training  ' % self.epoch, unit='it', total=len(self.train_dataloader)) as pbar:\n","            for it, items in enumerate(self.train_dataloader):\n","                quest, img, answer = items['question'], items['image'], items['answer']\n","                out = self.model(quest, img).contiguous()\n","                self.optim.zero_grad()\n","                answer = torch.stack([self.vocab.encode_answer(preprocess_sentence(ans, self.vocab.tokenizer)) for ans in answer]).to(self.device)\n","                loss = self.loss_fn(out.view(-1, self.vocab.total_answers), answer.view(-1))\n","                loss.backward()\n","\n","                self.optim.step()\n","                this_loss = loss.item()\n","                running_loss += this_loss\n","\n","                pbar.set_postfix({'loss': running_loss / (it + 1), 'lr':self.scheduler.get_last_lr()[0]})\n","                pbar.update()\n","        self.scheduler.step()\n","\n","        return running_loss / len(self.train_dataloader)\n","\n","    def start(self):\n","        if os.path.isfile(os.path.join(self.checkpoint_path, \"last_model.pth\")):\n","            checkpoint = self.load_checkpoint(os.path.join(self.checkpoint_path, \"last_model.pth\"))\n","            self.epoch = checkpoint[\"epoch\"] + 1\n","            print(\"Resuming from epoch %d\" % self.epoch)\n","            patience = 0\n","        else:\n","            self.score_value = .0\n","            patience = 0\n","\n","        while True:\n","            train_loss = self.train()\n","\n","            # val scores\n","            scores = self.evaluate_metrics(self.valid_dataloader)\n","            with open(os.path.join(self.checkpoint_path, \"log.txt\"), \"a\") as f:\n","                f.write(f\"Epoch {self.epoch:2d} - Training loss: {train_loss:.4f} - Validation wups: {scores['wups']:.4f} - Validation em: {scores['em']:.4f} - Validation f1: {scores['f1']:.4f} - Validation cider: {scores['cider']:.4f}\\n\")\n","\n","            print(f\"Validation wups: {scores['wups']:.4f} - em: {scores['em']:.4f} - f1: {scores['f1']:.4f} - cider: {scores['cider']:.4f}\")\n","            val_score = scores[self.score]\n","\n","            # Prepare for next epoch\n","            best = False\n","            if val_score > self.score_value:\n","                self.score_value = val_score\n","                patience = 0\n","                best = True\n","            else:\n","                patience += 1\n","\n","            exit_train = False\n","            if patience == self.patience:\n","                print('Patience reached.')\n","                exit_train = True\n","\n","            self.save_checkpoint()\n","\n","            if best:\n","                shutil.copy(os.path.join(self.checkpoint_path, \"last_model.pth\"),\n","                        os.path.join(self.checkpoint_path, \"best_model.pth\"))\n","\n","            if exit_train:\n","                break\n","\n","            self.epoch += 1\n","\n","    def get_predictions(self):\n","        if not os.path.isfile(os.path.join(self.checkpoint_path, 'best_model.pth')):\n","            print(\"Prediction require the model must be trained. There is no weights to load for model prediction!\")\n","            raise FileNotFoundError(\"Make sure your checkpoint path is correct or the best_model.pth is available in your checkpoint path\")\n","\n","        self.load_checkpoint(os.path.join(self.checkpoint_path, \"best_model.pth\"))\n","\n","        self.model.eval()\n","        img_path=[]\n","        quests_result=[]\n","        gts=[]\n","        preds=[]\n","        wups=0.\n","        em=0.\n","        f1=0.\n","        cider=0.\n","        with tqdm(desc='Getting predictions: ', unit='it', total=len(self.test_dataloader)) as pbar:\n","            for it, items in enumerate(self.test_dataloader):\n","                quest, img, answers = items['question'], items['image'], items['answer']\n","                with torch.no_grad():\n","                    outs = self.model(items['question'], items['image'])\n","\n","                answers_gen = self.vocab.decode_answer(outs.argmax(dim=-1), join_word=True)\n","\n","                img_path.extend(img)\n","                quests_result.extend(quest)\n","                gts.extend(answers)\n","                preds.extend(answers_gen)\n","                wups+=self.compute_score.wup(answers, answers_gen)\n","                em+=self.compute_score.em(answers, answers_gen)\n","                f1+=self.compute_score.f1_token(answers, answers_gen)\n","                cider+=self.compute_score.cider_score(answers, answers_gen)\n","\n","                pbar.update()\n","\n","        results={\n","            \"img_path\": img_path,\n","            \"question\": quests_result,\n","            \"ground_truth\":gts,\n","            \"predict\": preds,\n","        }\n","\n","        scores ={\n","            'wups':wups/len(self.test_dataloader),\n","            'em':em/len(self.test_dataloader),\n","            'f1':f1/len(self.test_dataloader),\n","            'cider':cider/len(self.test_dataloader)\n","        }\n","        print(f\"Evaluation scores on test - wups: {scores['wups']:.4f} - em: {scores['em']:.4f} - f1: {scores['f1']:.4f} - cider: {scores['cider']:.4f}\")\n","\n","        df = pd.DataFrame(results)\n","        df.to_csv(os.path.join(self.checkpoint_path,'result.csv'), index=False)\n","        print(f\"Save result to: {os.path.join(self.checkpoint_path,'result.csv')}\")"]},{"cell_type":"code","source":["task = ClassificationTask(CONFIG)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":484,"referenced_widgets":["221d77f27a63493f97db95d2a4de1918","3ee0e9b484014facaf21612aa63bfc85","3c4822d011664a1989462ac87d7d2e8e","44c4941c431f45e4806a41980f1f5a3e","e7ad1748174a4895a380885bcf48ce44","a53ccd6281d04c6cbf96b2d507bd3780","e880a197de7c4b12ac80c3e59b6e9246","929b81f707f54b1ba0e83d56d34cffbc","a7d4fb6e39344517bf9929fb3036970b","e231034207704f70b9c02a132707998f","864bedabbdaa47789232a2abf397723a","471b19aabc3247b5a5870dd52bcb4d10","f1d5f45f64c349c497ff4489858692a4","71a9d50db7064bbe9dd6f42b36a342b1","1bd0b286b5b741978c6e0e417d4390c0","36128b52c2a341a89e47fb987a15d136","baae1498a610427d8642d77bb35846d9","2e82e28a5e4844e098d55784a54d9c7e","ad517428c2544cf1bba0cce2fd11c5df","d20c5c6e62cf4477907151b3e55bafb0","21c2df04523e44969e8389c8a04377f0","564b94ea570543529a4edc4f5fe964b1","5aafb21c06534d29924c9a8b4201c9c5","86907cea84324b738717ea4c8890b0c0","f008b58598db4e0c868c0cab457e0007","9cddfe8bbdc74ad1a54ddd636c19bb29","dc2e662205cf4087a828bc1f1ea8a757","b5c3eec2226542fdb5885211c603f8f5","f4001d4cb7e8440e900fc06f16f2c38a","7ca5436dd9484613b64c5c2f4e6c89b2","3b5e40e322f2408986d073d272bd72ba","78ee35776bd64488898d36ea28e61e3a","6c78b19fc0b94887a6b3e48d0b937e63","31210135828d4ad3ac35033c418846b5","8123e2c5bc99414eaca86c11771d1361","20936e36f05d45a4a56236755fb1a2ca","12dc9661944f49d58c005406d191c9af","56f88ec234084d209dd4e94d859f1768","03ef421154cd41da811232db756b7f8c","fc36d8b25f594fec93e6756d2143ca97","2df8c605f07244f39f964c98600a98fb","53a56fb2f376457c87e40ce333af78af","6deaa102ded242b7b596749d007488e6","51def26d938c44b885f7a1baf00d9c84","4fb1c19ca55f43e6b72e9e86e77ccb46","514298e6e46a4c7a84ca752623e6db6a","e6ef746b5bb34862898869685d2c3d9c","c182f7ded4dc4622a44707aab095f87a","48ad3ec118d748f1941da12d25930403","05b5945ba8224accbde028e1c5da04a6","7808cc2b6a2648d4a85ccd60a56eac86","e93344d39bfd42f59d256bac5dffc989","148d752ef4d94a07abd91f3aba5ec265","d9eeef76bc144cacbf893ddf53b267a8","d3be6026f623442ca6f250a2b78002ab","0765bdd4261e49b088646dd18ca7c1c0","16590b7c12bf446a834c79127ddaf2b3","d8cd1dbca65a4ef98a4fc119d301af81","120c9e4ebb3f486797f1d5dd290d7e83","6413187bb8a64477ab3124f4d9b12d79","e6bb54078d64423ebd4645ddb345ab97","b6631538c5ea43c585604e0ab8d003e3","68276dfadad8443496aee0586156a612","ee8c1ca87daa45d185b379e6debc9c35","abc9c9fff31843f68ade5fdc5eba41a6","18476f7178a944a897d7d35a04ca6e62","5ba8c3e964164cb5846808daec97fe8f","6f1d9d37090247e7974ff9e72db929cb","c8d69fe6bbdb467baea2cfcf9a268aed","17f508d8047c494b81ed6588bb8ba5b0","40ca67683f7443ff8977e416c5887c22","e43f07decdb5434bad1954f00863a35d","140fed259ae14bfb9d40e3ca93be302d","447ea9dab37f4e6ebb36ba0e273f23a5","c83cd8f60d154d739125294858b90cf3","af5cd8a461fb451db8642bf2581631f3","5cbbf9a82a9640dd89c3befcbfa68a85","0f551a11f186433488b9b85afaec0dd6","d3d0671247124f0bb6d7e75d31f286c2","38ed74c059024cbeb840480a58141c7f","c83dfc70d4e749c19680cf260cbbe8b9","a49702bee0c34fe2940d87009c5ab220","562205d12c5e456da91013af88fee962","e62f3104091a4724b048611e6a52aff9","e4e332e4cb8d43cc87a7502b9eb5fe82","e7ae2091c9ae4b0a96d0e79f8e22299c","53b4e386ccdc4683994aaa375ffdb0d4","a97883091b644242b2004614a38b1ca8"]},"id":"G1EyorZTPNbR","executionInfo":{"status":"ok","timestamp":1704536441683,"user_tz":-420,"elapsed":70607,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}},"outputId":"de253241-7038-41ec-f162-c7650ceb91e6"},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading vocab from /content/drive/MyDrive/ViVQA-Models/vit_phobert_classification/vocab.bin\n","Loading data\n","[INFO] Train size: 9455\n","[INFO] Valid size: 2364\n","[INFO] Test size: 2987\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:72: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/557 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"221d77f27a63493f97db95d2a4de1918"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["vocab.txt:   0%|          | 0.00/895k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"471b19aabc3247b5a5870dd52bcb4d10"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["bpe.codes:   0%|          | 0.00/1.14M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5aafb21c06534d29924c9a8b4201c9c5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/3.13M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"31210135828d4ad3ac35033c418846b5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/543M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4fb1c19ca55f43e6b72e9e86e77ccb46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0765bdd4261e49b088646dd18ca7c1c0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/502 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ba8c3e964164cb5846808daec97fe8f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["pytorch_model.bin:   0%|          | 0.00/346M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f551a11f186433488b9b85afaec0dd6"}},"metadata":{}}]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r01z-tKceoYG","outputId":"686e090f-6807-4f88-b043-4a38f1819ec3","executionInfo":{"status":"ok","timestamp":1704541013162,"user_tz":-420,"elapsed":4571510,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading checkpoint from /content/drive/MyDrive/ViVQA-Models/vit_phobert_classification/last_model.pth\n","Resuming from epoch 33\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 33 - Training  : 100%|██████████| 296/296 [03:38<00:00,  1.35it/s, loss=0.999, lr=1e-5]\n","Epoch 33 - Evaluation: 100%|██████████| 74/74 [00:57<00:00,  1.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4389 - em: 0.4389 - f1: 0.5113 - cider: 2.0790\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 34 - Training  : 100%|██████████| 296/296 [03:41<00:00,  1.34it/s, loss=1.02, lr=9.5e-6]\n","Epoch 34 - Evaluation: 100%|██████████| 74/74 [00:55<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4458 - em: 0.4458 - f1: 0.5168 - cider: 2.1226\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 35 - Training  : 100%|██████████| 296/296 [03:39<00:00,  1.35it/s, loss=0.954, lr=9.03e-6]\n","Epoch 35 - Evaluation: 100%|██████████| 74/74 [00:54<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4425 - em: 0.4425 - f1: 0.5152 - cider: 2.0780\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 36 - Training  : 100%|██████████| 296/296 [03:37<00:00,  1.36it/s, loss=0.894, lr=8.57e-6]\n","Epoch 36 - Evaluation: 100%|██████████| 74/74 [00:55<00:00,  1.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4523 - em: 0.4523 - f1: 0.5220 - cider: 2.1254\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 37 - Training  : 100%|██████████| 296/296 [03:41<00:00,  1.34it/s, loss=0.843, lr=8.15e-6]\n","Epoch 37 - Evaluation: 100%|██████████| 74/74 [00:54<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4606 - em: 0.4606 - f1: 0.5304 - cider: 2.1662\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 38 - Training  : 100%|██████████| 296/296 [03:40<00:00,  1.34it/s, loss=0.797, lr=7.74e-6]\n","Epoch 38 - Evaluation: 100%|██████████| 74/74 [00:54<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4552 - em: 0.4552 - f1: 0.5269 - cider: 2.1283\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 39 - Training  : 100%|██████████| 296/296 [03:39<00:00,  1.35it/s, loss=0.759, lr=7.35e-6]\n","Epoch 39 - Evaluation: 100%|██████████| 74/74 [00:55<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4589 - em: 0.4589 - f1: 0.5307 - cider: 2.1390\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 40 - Training  : 100%|██████████| 296/296 [03:39<00:00,  1.35it/s, loss=0.72, lr=6.98e-6]\n","Epoch 40 - Evaluation: 100%|██████████| 74/74 [00:54<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4627 - em: 0.4627 - f1: 0.5344 - cider: 2.1529\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 41 - Training  : 100%|██████████| 296/296 [03:39<00:00,  1.35it/s, loss=0.691, lr=6.63e-6]\n","Epoch 41 - Evaluation: 100%|██████████| 74/74 [00:54<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4653 - em: 0.4653 - f1: 0.5356 - cider: 2.1766\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 42 - Training  : 100%|██████████| 296/296 [03:40<00:00,  1.35it/s, loss=0.654, lr=6.3e-6]\n","Epoch 42 - Evaluation: 100%|██████████| 74/74 [00:55<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4631 - em: 0.4631 - f1: 0.5328 - cider: 2.1627\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 43 - Training  : 100%|██████████| 296/296 [03:38<00:00,  1.35it/s, loss=0.627, lr=5.99e-6]\n","Epoch 43 - Evaluation: 100%|██████████| 74/74 [00:54<00:00,  1.35it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4708 - em: 0.4708 - f1: 0.5412 - cider: 2.1988\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 44 - Training  : 100%|██████████| 296/296 [03:40<00:00,  1.34it/s, loss=0.612, lr=5.69e-6]\n","Epoch 44 - Evaluation: 100%|██████████| 74/74 [00:53<00:00,  1.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4640 - em: 0.4640 - f1: 0.5358 - cider: 2.1556\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 45 - Training  : 100%|██████████| 296/296 [03:38<00:00,  1.35it/s, loss=0.588, lr=5.4e-6]\n","Epoch 45 - Evaluation: 100%|██████████| 74/74 [00:53<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4627 - em: 0.4627 - f1: 0.5343 - cider: 2.1500\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 46 - Training  : 100%|██████████| 296/296 [03:37<00:00,  1.36it/s, loss=0.563, lr=5.13e-6]\n","Epoch 46 - Evaluation: 100%|██████████| 74/74 [00:53<00:00,  1.37it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4602 - em: 0.4602 - f1: 0.5320 - cider: 2.1478\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 47 - Training  : 100%|██████████| 296/296 [03:39<00:00,  1.35it/s, loss=0.548, lr=4.88e-6]\n","Epoch 47 - Evaluation: 100%|██████████| 74/74 [00:54<00:00,  1.36it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4691 - em: 0.4691 - f1: 0.5396 - cider: 2.1908\n"]},{"output_type":"stream","name":"stderr","text":["Epoch 48 - Training  : 100%|██████████| 296/296 [03:38<00:00,  1.35it/s, loss=0.53, lr=4.63e-6]\n","Epoch 48 - Evaluation: 100%|██████████| 74/74 [00:55<00:00,  1.34it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Validation wups: 0.4674 - em: 0.4674 - f1: 0.5372 - cider: 2.1830\n","Patience reached.\n"]}],"source":["task.start()"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"FY9add1leraI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1704541090158,"user_tz":-420,"elapsed":77015,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}},"outputId":"dd1b43f4-9e96-4013-81ce-7e1fe5905f02"},"outputs":[{"output_type":"stream","name":"stdout","text":["Loading checkpoint from /content/drive/MyDrive/ViVQA-Models/vit_phobert_classification/best_model.pth\n"]},{"output_type":"stream","name":"stderr","text":["Getting predictions: 100%|██████████| 94/94 [01:12<00:00,  1.30it/s]"]},{"output_type":"stream","name":"stdout","text":["Evaluation scores on test - wups: 0.4646 - em: 0.4646 - f1: 0.5157 - cider: 2.0841\n","Save result to: /content/drive/MyDrive/ViVQA-Models/vit_phobert_classification/result.csv\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}],"source":["task.get_predictions()"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"GDr3ly85PG8P","executionInfo":{"status":"ok","timestamp":1704541097837,"user_tz":-420,"elapsed":7693,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"outputs":[],"source":["!pip install -q torchinfo"]},{"cell_type":"code","source":["from torchinfo import summary\n","summary(task.model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ga75XELLKXmz","executionInfo":{"status":"ok","timestamp":1704541097838,"user_tz":-420,"elapsed":19,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}},"outputId":"c40c8845-1374-4e87-d492-da77f1e74647"},"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["==========================================================================================\n","Layer (type:depth-idx)                                            Param #\n","==========================================================================================\n","ViTmBERTClassification                                            --\n","├─RobertaEmbedding: 1-1                                           --\n","│    └─TextBert: 2-1                                              --\n","│    │    └─RobertaEmbeddings: 3-1                                (49,353,216)\n","│    │    └─RobertaEncoder: 3-2                                   (85,054,464)\n","│    └─Linear: 2-2                                                393,728\n","│    └─GELU: 2-3                                                  --\n","│    └─Dropout: 2-4                                               --\n","├─ViTEmbedding: 1-2                                               --\n","│    └─ViTModel: 2-5                                              --\n","│    │    └─ViTEmbeddings: 3-3                                    (742,656)\n","│    │    └─ViTEncoder: 3-4                                       (85,054,464)\n","│    │    └─LayerNorm: 3-5                                        (1,536)\n","│    │    └─ViTPooler: 3-6                                        (590,592)\n","│    └─Linear: 2-6                                                393,728\n","│    └─GELU: 2-7                                                  --\n","│    └─Dropout: 2-8                                               --\n","├─Linear: 1-3                                                     262,656\n","├─Dropout: 1-4                                                    --\n","├─LayerNorm: 1-5                                                  1,024\n","├─Linear: 1-6                                                     180,063\n","==========================================================================================\n","Total params: 222,028,127\n","Trainable params: 1,231,199\n","Non-trainable params: 220,796,928\n","=========================================================================================="]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["print(task.model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OQxx6ZqqKaBJ","executionInfo":{"status":"ok","timestamp":1704541097838,"user_tz":-420,"elapsed":16,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}},"outputId":"287332f8-79f8-4218-c30f-3021b18402f5"},"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["ViTmBERTClassification(\n","  (text_embedding): RobertaEmbedding(\n","    (embedding): TextBert(\n","      (embeddings): RobertaEmbeddings(\n","        (word_embeddings): Embedding(64001, 768, padding_idx=1)\n","        (position_embeddings): Embedding(258, 768, padding_idx=1)\n","        (token_type_embeddings): Embedding(1, 768)\n","        (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): RobertaEncoder(\n","        (layer): ModuleList(\n","          (0-11): 12 x RobertaLayer(\n","            (attention): RobertaAttention(\n","              (self): RobertaSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): RobertaSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): RobertaIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): RobertaOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (proj): Linear(in_features=768, out_features=512, bias=True)\n","    (gelu): GELU(approximate='none')\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (vision_encoder): ViTEmbedding(\n","    (backbone): ViTModel(\n","      (embeddings): ViTEmbeddings(\n","        (patch_embeddings): ViTPatchEmbeddings(\n","          (projection): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n","        )\n","        (dropout): Dropout(p=0.0, inplace=False)\n","      )\n","      (encoder): ViTEncoder(\n","        (layer): ModuleList(\n","          (0-11): 12 x ViTLayer(\n","            (attention): ViTAttention(\n","              (attention): ViTSelfAttention(\n","                (query): Linear(in_features=768, out_features=768, bias=True)\n","                (key): Linear(in_features=768, out_features=768, bias=True)\n","                (value): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","              (output): ViTSelfOutput(\n","                (dense): Linear(in_features=768, out_features=768, bias=True)\n","                (dropout): Dropout(p=0.0, inplace=False)\n","              )\n","            )\n","            (intermediate): ViTIntermediate(\n","              (dense): Linear(in_features=768, out_features=3072, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): ViTOutput(\n","              (dense): Linear(in_features=3072, out_features=768, bias=True)\n","              (dropout): Dropout(p=0.0, inplace=False)\n","            )\n","            (layernorm_before): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","            (layernorm_after): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","          )\n","        )\n","      )\n","      (layernorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n","      (pooler): ViTPooler(\n","        (dense): Linear(in_features=768, out_features=768, bias=True)\n","        (activation): Tanh()\n","      )\n","    )\n","    (proj): Linear(in_features=768, out_features=512, bias=True)\n","    (gelu): GELU(approximate='none')\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (fusion): Linear(in_features=512, out_features=512, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n","  (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n","  (proj): Linear(in_features=512, out_features=351, bias=True)\n",")\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"_ILjhFetKcYo","executionInfo":{"status":"ok","timestamp":1704541097838,"user_tz":-420,"elapsed":13,"user":{"displayName":"Hiếu Nguyễn","userId":"03621851764524954359"}}},"execution_count":25,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"1AY1eg3dl3EzHU_fEy7nPukXcjCrw7YLF","timestamp":1704525952491}]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"widgets":{"application/vnd.jupyter.widget-state+json":{"221d77f27a63493f97db95d2a4de1918":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ee0e9b484014facaf21612aa63bfc85","IPY_MODEL_3c4822d011664a1989462ac87d7d2e8e","IPY_MODEL_44c4941c431f45e4806a41980f1f5a3e"],"layout":"IPY_MODEL_e7ad1748174a4895a380885bcf48ce44"}},"3ee0e9b484014facaf21612aa63bfc85":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a53ccd6281d04c6cbf96b2d507bd3780","placeholder":"​","style":"IPY_MODEL_e880a197de7c4b12ac80c3e59b6e9246","value":"config.json: 100%"}},"3c4822d011664a1989462ac87d7d2e8e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_929b81f707f54b1ba0e83d56d34cffbc","max":557,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a7d4fb6e39344517bf9929fb3036970b","value":557}},"44c4941c431f45e4806a41980f1f5a3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e231034207704f70b9c02a132707998f","placeholder":"​","style":"IPY_MODEL_864bedabbdaa47789232a2abf397723a","value":" 557/557 [00:00&lt;00:00, 29.2kB/s]"}},"e7ad1748174a4895a380885bcf48ce44":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a53ccd6281d04c6cbf96b2d507bd3780":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e880a197de7c4b12ac80c3e59b6e9246":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"929b81f707f54b1ba0e83d56d34cffbc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a7d4fb6e39344517bf9929fb3036970b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e231034207704f70b9c02a132707998f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"864bedabbdaa47789232a2abf397723a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"471b19aabc3247b5a5870dd52bcb4d10":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f1d5f45f64c349c497ff4489858692a4","IPY_MODEL_71a9d50db7064bbe9dd6f42b36a342b1","IPY_MODEL_1bd0b286b5b741978c6e0e417d4390c0"],"layout":"IPY_MODEL_36128b52c2a341a89e47fb987a15d136"}},"f1d5f45f64c349c497ff4489858692a4":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_baae1498a610427d8642d77bb35846d9","placeholder":"​","style":"IPY_MODEL_2e82e28a5e4844e098d55784a54d9c7e","value":"vocab.txt: 100%"}},"71a9d50db7064bbe9dd6f42b36a342b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ad517428c2544cf1bba0cce2fd11c5df","max":895321,"min":0,"orientation":"horizontal","style":"IPY_MODEL_d20c5c6e62cf4477907151b3e55bafb0","value":895321}},"1bd0b286b5b741978c6e0e417d4390c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_21c2df04523e44969e8389c8a04377f0","placeholder":"​","style":"IPY_MODEL_564b94ea570543529a4edc4f5fe964b1","value":" 895k/895k [00:00&lt;00:00, 912kB/s]"}},"36128b52c2a341a89e47fb987a15d136":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"baae1498a610427d8642d77bb35846d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2e82e28a5e4844e098d55784a54d9c7e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ad517428c2544cf1bba0cce2fd11c5df":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d20c5c6e62cf4477907151b3e55bafb0":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"21c2df04523e44969e8389c8a04377f0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"564b94ea570543529a4edc4f5fe964b1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5aafb21c06534d29924c9a8b4201c9c5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_86907cea84324b738717ea4c8890b0c0","IPY_MODEL_f008b58598db4e0c868c0cab457e0007","IPY_MODEL_9cddfe8bbdc74ad1a54ddd636c19bb29"],"layout":"IPY_MODEL_dc2e662205cf4087a828bc1f1ea8a757"}},"86907cea84324b738717ea4c8890b0c0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b5c3eec2226542fdb5885211c603f8f5","placeholder":"​","style":"IPY_MODEL_f4001d4cb7e8440e900fc06f16f2c38a","value":"bpe.codes: 100%"}},"f008b58598db4e0c868c0cab457e0007":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7ca5436dd9484613b64c5c2f4e6c89b2","max":1135173,"min":0,"orientation":"horizontal","style":"IPY_MODEL_3b5e40e322f2408986d073d272bd72ba","value":1135173}},"9cddfe8bbdc74ad1a54ddd636c19bb29":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78ee35776bd64488898d36ea28e61e3a","placeholder":"​","style":"IPY_MODEL_6c78b19fc0b94887a6b3e48d0b937e63","value":" 1.14M/1.14M [00:00&lt;00:00, 1.15MB/s]"}},"dc2e662205cf4087a828bc1f1ea8a757":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5c3eec2226542fdb5885211c603f8f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f4001d4cb7e8440e900fc06f16f2c38a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7ca5436dd9484613b64c5c2f4e6c89b2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b5e40e322f2408986d073d272bd72ba":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"78ee35776bd64488898d36ea28e61e3a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c78b19fc0b94887a6b3e48d0b937e63":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"31210135828d4ad3ac35033c418846b5":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_8123e2c5bc99414eaca86c11771d1361","IPY_MODEL_20936e36f05d45a4a56236755fb1a2ca","IPY_MODEL_12dc9661944f49d58c005406d191c9af"],"layout":"IPY_MODEL_56f88ec234084d209dd4e94d859f1768"}},"8123e2c5bc99414eaca86c11771d1361":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03ef421154cd41da811232db756b7f8c","placeholder":"​","style":"IPY_MODEL_fc36d8b25f594fec93e6756d2143ca97","value":"tokenizer.json: 100%"}},"20936e36f05d45a4a56236755fb1a2ca":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_2df8c605f07244f39f964c98600a98fb","max":3132320,"min":0,"orientation":"horizontal","style":"IPY_MODEL_53a56fb2f376457c87e40ce333af78af","value":3132320}},"12dc9661944f49d58c005406d191c9af":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6deaa102ded242b7b596749d007488e6","placeholder":"​","style":"IPY_MODEL_51def26d938c44b885f7a1baf00d9c84","value":" 3.13M/3.13M [00:01&lt;00:00, 2.21MB/s]"}},"56f88ec234084d209dd4e94d859f1768":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"03ef421154cd41da811232db756b7f8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc36d8b25f594fec93e6756d2143ca97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2df8c605f07244f39f964c98600a98fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"53a56fb2f376457c87e40ce333af78af":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6deaa102ded242b7b596749d007488e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"51def26d938c44b885f7a1baf00d9c84":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fb1c19ca55f43e6b72e9e86e77ccb46":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_514298e6e46a4c7a84ca752623e6db6a","IPY_MODEL_e6ef746b5bb34862898869685d2c3d9c","IPY_MODEL_c182f7ded4dc4622a44707aab095f87a"],"layout":"IPY_MODEL_48ad3ec118d748f1941da12d25930403"}},"514298e6e46a4c7a84ca752623e6db6a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_05b5945ba8224accbde028e1c5da04a6","placeholder":"​","style":"IPY_MODEL_7808cc2b6a2648d4a85ccd60a56eac86","value":"pytorch_model.bin: 100%"}},"e6ef746b5bb34862898869685d2c3d9c":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e93344d39bfd42f59d256bac5dffc989","max":542923308,"min":0,"orientation":"horizontal","style":"IPY_MODEL_148d752ef4d94a07abd91f3aba5ec265","value":542923308}},"c182f7ded4dc4622a44707aab095f87a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d9eeef76bc144cacbf893ddf53b267a8","placeholder":"​","style":"IPY_MODEL_d3be6026f623442ca6f250a2b78002ab","value":" 543M/543M [00:01&lt;00:00, 338MB/s]"}},"48ad3ec118d748f1941da12d25930403":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05b5945ba8224accbde028e1c5da04a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7808cc2b6a2648d4a85ccd60a56eac86":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e93344d39bfd42f59d256bac5dffc989":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"148d752ef4d94a07abd91f3aba5ec265":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d9eeef76bc144cacbf893ddf53b267a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d3be6026f623442ca6f250a2b78002ab":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0765bdd4261e49b088646dd18ca7c1c0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_16590b7c12bf446a834c79127ddaf2b3","IPY_MODEL_d8cd1dbca65a4ef98a4fc119d301af81","IPY_MODEL_120c9e4ebb3f486797f1d5dd290d7e83"],"layout":"IPY_MODEL_6413187bb8a64477ab3124f4d9b12d79"}},"16590b7c12bf446a834c79127ddaf2b3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6bb54078d64423ebd4645ddb345ab97","placeholder":"​","style":"IPY_MODEL_b6631538c5ea43c585604e0ab8d003e3","value":"preprocessor_config.json: 100%"}},"d8cd1dbca65a4ef98a4fc119d301af81":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_68276dfadad8443496aee0586156a612","max":160,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ee8c1ca87daa45d185b379e6debc9c35","value":160}},"120c9e4ebb3f486797f1d5dd290d7e83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_abc9c9fff31843f68ade5fdc5eba41a6","placeholder":"​","style":"IPY_MODEL_18476f7178a944a897d7d35a04ca6e62","value":" 160/160 [00:00&lt;00:00, 11.5kB/s]"}},"6413187bb8a64477ab3124f4d9b12d79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e6bb54078d64423ebd4645ddb345ab97":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6631538c5ea43c585604e0ab8d003e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"68276dfadad8443496aee0586156a612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee8c1ca87daa45d185b379e6debc9c35":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"abc9c9fff31843f68ade5fdc5eba41a6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"18476f7178a944a897d7d35a04ca6e62":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5ba8c3e964164cb5846808daec97fe8f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6f1d9d37090247e7974ff9e72db929cb","IPY_MODEL_c8d69fe6bbdb467baea2cfcf9a268aed","IPY_MODEL_17f508d8047c494b81ed6588bb8ba5b0"],"layout":"IPY_MODEL_40ca67683f7443ff8977e416c5887c22"}},"6f1d9d37090247e7974ff9e72db929cb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e43f07decdb5434bad1954f00863a35d","placeholder":"​","style":"IPY_MODEL_140fed259ae14bfb9d40e3ca93be302d","value":"config.json: 100%"}},"c8d69fe6bbdb467baea2cfcf9a268aed":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_447ea9dab37f4e6ebb36ba0e273f23a5","max":502,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c83cd8f60d154d739125294858b90cf3","value":502}},"17f508d8047c494b81ed6588bb8ba5b0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_af5cd8a461fb451db8642bf2581631f3","placeholder":"​","style":"IPY_MODEL_5cbbf9a82a9640dd89c3befcbfa68a85","value":" 502/502 [00:00&lt;00:00, 21.5kB/s]"}},"40ca67683f7443ff8977e416c5887c22":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e43f07decdb5434bad1954f00863a35d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"140fed259ae14bfb9d40e3ca93be302d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"447ea9dab37f4e6ebb36ba0e273f23a5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c83cd8f60d154d739125294858b90cf3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"af5cd8a461fb451db8642bf2581631f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5cbbf9a82a9640dd89c3befcbfa68a85":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"0f551a11f186433488b9b85afaec0dd6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d3d0671247124f0bb6d7e75d31f286c2","IPY_MODEL_38ed74c059024cbeb840480a58141c7f","IPY_MODEL_c83dfc70d4e749c19680cf260cbbe8b9"],"layout":"IPY_MODEL_a49702bee0c34fe2940d87009c5ab220"}},"d3d0671247124f0bb6d7e75d31f286c2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_562205d12c5e456da91013af88fee962","placeholder":"​","style":"IPY_MODEL_e62f3104091a4724b048611e6a52aff9","value":"pytorch_model.bin: 100%"}},"38ed74c059024cbeb840480a58141c7f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e4e332e4cb8d43cc87a7502b9eb5fe82","max":345636463,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e7ae2091c9ae4b0a96d0e79f8e22299c","value":345636463}},"c83dfc70d4e749c19680cf260cbbe8b9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_53b4e386ccdc4683994aaa375ffdb0d4","placeholder":"​","style":"IPY_MODEL_a97883091b644242b2004614a38b1ca8","value":" 346M/346M [00:01&lt;00:00, 332MB/s]"}},"a49702bee0c34fe2940d87009c5ab220":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"562205d12c5e456da91013af88fee962":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e62f3104091a4724b048611e6a52aff9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e4e332e4cb8d43cc87a7502b9eb5fe82":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e7ae2091c9ae4b0a96d0e79f8e22299c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"53b4e386ccdc4683994aaa375ffdb0d4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a97883091b644242b2004614a38b1ca8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}